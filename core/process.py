import json, re
from pathlib import Path
from .helper import *
from .config import *
from .STB import IPTVClient
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from datetime import datetime, timedelta, timezone


def get_iptv_raw():
    print("è·å– IPTV åŸå§‹æ•°æ®...")
    client = IPTVClient()
    client.login()
    client.auth()
    client.portal_auth()
    channels = client.get_channels()
    with open("data/raw.json", "w", encoding="utf-8") as f:
        json.dump(channels, f, ensure_ascii=False, indent=4)


def gen_iptv_json():
    with open("data/raw.json", "r", encoding="utf-8") as file:
        json_data = json.load(file)

    results = []
    not_found = []

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(process_channel, ch): ch for ch in json_data}
        for future in tqdm(
            as_completed(futures), total=len(futures), desc="æ ¼å¼åŒ– IPTV åŸå§‹æ•°æ®..."
        ):
            record, warning = future.result()
            if record:
                results.append(record)
            if warning:
                not_found.append(warning)

    try:
        results.sort(key=lambda x: int(x["tvg_id"]))
    except ValueError:
        results.sort(key=lambda x: x["tvg_id"])

    with open("data/iptv.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    if not_found:
        print("=== æœªæ‰¾åˆ°å•æ’­åœ°å€çš„é¢‘é“ ===")
        for msg in not_found:
            print(msg)


def gen_m3u_playlist(
    output_path="playlist",
    json_file="data/iptv.json",
    mode: str = "uni",
    sort_file: str | None = None,
) -> None:
    """
    ç”Ÿæˆ M3U æ’­æ”¾åˆ—è¡¨ï¼Œå¯æŒ‰ sort_file æŒ‡å®šé¡ºåºå†™å…¥
    :param json_file: JSON æ•°æ®æ–‡ä»¶
    :param output_file: è¾“å‡ºçš„ .m3u è·¯å¾„
    :param mode: 'uni' å•æ’­ï¼›'mul' ç»„æ’­
    :param sort_file: åŒ…å« ChannelName çš„æ’åºæ–‡ä»¶ï¼Œä¸€è¡Œä¸€ä¸ªï¼›è‹¥ä¸º None åˆ™ä¿æŒåŸé¡ºåº
    """
    from pathlib import Path

    Path(output_path).mkdir(parents=True, exist_ok=True)

    with Path(json_file).open("r", encoding="utf-8") as fp:
        channels: list[dict] = json.load(fp)

    if sort_file:
        with Path(sort_file).open("r", encoding="utf-8") as fp:
            order_list = [
                line.strip()
                for line in fp
                if line.strip() and not line.strip().startswith("#")
            ]

        bucket: dict[str, list[dict]] = {}
        for ch in channels:
            bucket.setdefault(ch.get("ChannelName", ""), []).append(ch)

        ordered_channels: list[dict] = []
        remaining_channels: list[dict] = []

        for tid in order_list:
            ordered_channels.extend(bucket.pop(tid, []))

        for remaining in bucket.values():
            remaining_channels.extend(remaining)

        high_channels = [
            ch for ch in remaining_channels if "é«˜æ¸…" in ch.get("ChannelName", "")
        ]
        low_channels = [
            ch for ch in remaining_channels if "é«˜æ¸…" not in ch.get("ChannelName", "")
        ]

        channels = ordered_channels + high_channels + low_channels

    if mode == "uni":
        output_file = f"{output_path}/unicast.m3u"
    elif mode == "mul":
        output_file = f"{output_path}/multicast.m3u"

    with Path(output_file).open("w", encoding="utf-8") as fp:
        fp.write(f'#EXTM3U url-tvg="{url_tvg}" \n')

        for ch in channels:
            catchup = ch.get("uni_playback")
            if catchup.startswith("rtsp://222") and mode == "uni":
                continue

            tvg_name = ch.get("tvg_name", "")

            tvg_logo = f"{logo_base}{tvg_name}.png"
            group_title = ch.get("group_title", "")

            if mode == "uni":
                url = ch.get("uni_live", "")
            elif mode == "mul":
                url = ch.get("udpxy_url", "").replace("rtp://", "rtp/")
                url = f"{udpxy_base_url}/{url}"
            if not url:
                continue

            extinf = (
                f"#EXTINF:-1 "
                f'tvg-name="{tvg_name}" '
                # f'tvg-id="{tvg_id}" '
                f'group-title="{group_title}" '
                f'tvg-logo="{tvg_logo}" '
            )

            if catchup:
                extinf += f'catchup="default" catchup-source="{catchup}"'

            extinf += f", {tvg_name}"
            fp.write(f"{extinf}\n{url}\n")

    print(f"æ’­æ”¾åˆ—è¡¨å·²ä¿å­˜åˆ° {output_file}")


def diff_channel_lists(json_file="data/raw.json", output_file="data/channels.txt"):
    """
    ä» JSON æ–‡ä»¶è¯»å– ChannelName å¹¶å†™å…¥æ–‡æœ¬æ–‡ä»¶ï¼ŒåŒæ—¶ä¸å·²æœ‰ channel.txt å¯¹æ¯”æ˜¯å¦ä¸€è‡´
    :param json_file: è¾“å…¥çš„ JSON æ–‡ä»¶è·¯å¾„
    :param output_file: è¾“å‡ºçš„ TXT æ–‡ä»¶è·¯å¾„
    """
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        json_channel_names = [
            item["ChannelName"] for item in data if "ChannelName" in item
        ]

        try:
            with open(output_file, "r", encoding="utf-8") as f:
                existing_channels = [line.strip() for line in f.readlines()]
        except FileNotFoundError:
            existing_channels = []
            print(f"{output_file} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°çš„æ–‡ä»¶")

        final_message = ""
        ifWrite = False

        if existing_channels == json_channel_names:
            final_message = "é¢‘é“åˆ—è¡¨æœªå˜åŠ¨"
        else:
            ifWrite = True
            added = [c for c in json_channel_names if c not in existing_channels]
            removed = [c for c in existing_channels if c not in json_channel_names]

            parts = []
            if added:
                parts.append("ä¸Šçº¿é¢‘é“: " + ", ".join(added))
            if removed:
                parts.append("ä¸‹çº¿é¢‘é“: " + ", ".join(removed))

            final_message = "\n".join(parts)

        print(final_message)

        if ifWrite == True:
            now_str = datetime.now().strftime("%Y-%m-%d")
            with open("data/channel-change.md", "a", encoding="utf-8") as f:
                f.write(f"#### æ—¶é—´: {now_str}\n")
                f.write(final_message + "\n\n")

        with open(output_file, "w", encoding="utf-8") as f:
            for name in json_channel_names:
                f.write(name + "\n")

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")


def generate_unused_multicast_m3u(
    json_file="data/raw.json", output_file="data/unused.m3u"
):
    used = []
    noUse = []
    with open(json_file, "r", encoding="utf-8") as file:
        json_data = json.load(file)
        for channel in json_data:

            if "ChannelURL" in channel and channel["ChannelURL"].startswith("igmp://"):
                url = channel["ChannelURL"].replace("igmp://", "")
                matches = re.findall(r"\b(?:\d{1,3}\.){3}(\d{1,3})\b", url)
                used.append(int(matches[0]))
        for i in range(0, 256):
            if i not in used:
                noUse.append(i)

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n")
        for ch in noUse:
            extinf = f"#EXTINF:-1 "
            extinf += f",{ch}"
            f.write(
                f"{extinf}\n{f'http://192.168.0.1:4022/rtp/239.253.240.{ch}:8000'}\n"
            )

    print(f"æœªä½¿ç”¨çš„ç»„æ’­åœ°å€å·²ä¿å­˜åˆ° {output_file}")


def probe_unused_multicast(
    json_file="data/raw.json",
    timeout=10,
    output_file="data/probe-unused.json",
    max_workers=1,
):
    """
    å¤šçº¿ç¨‹è°ƒç”¨ probe_info è·å–æœªä½¿ç”¨ç»„æ’­çš„ ffprobe JSONã€‚
    è¿”å›åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º {"addr": int, "info": dict}
    """
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    used = {
        int(m.group(1))
        for ch in data
        if (m := re.search(r"\b(?:\d{1,3}\.){3}(\d{1,3})\b", ch.get("ChannelURL", "")))
    }

    unused = [i for i in range(1, 256) if i not in used]

    def worker(ch):
        url = f"{udpxy_base_url}/rtp/239.253.240.{ch}:8000"
        print("Probing:", url)
        info = probe_info_by_url(url, timeout=timeout)
        return {"addr": ch, "info": info}

    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for res in executor.map(worker, unused):
            results.append(res)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=4)

    return results


def probe_unicast(
    json_file="data/raw.json",
    timeout=10,
    output_file="data/probe-unicast.json",
    max_workers=8,
):
    """
    å¤šçº¿ç¨‹è°ƒç”¨ probe_info è·å–å•æ’­çš„ ffprobe JSONã€‚
    è¿”å›åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º {"name": str, "info": dict}
    """
    channels = []
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    for channel in data:
        if "ChannelSDP" in channel:
            match = re.search(r"rtsp://\S+", channel["ChannelSDP"])
            if match:
                url = match.group(0)
                channels.append({"name": channel["ChannelName"], "url": url})

    def worker(ch):
        print("Probing:", ch["name"])
        info = probe_info_by_url(ch["url"], timeout=timeout)
        return {"name": ch["name"], "info": info}

    results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for res in executor.map(worker, channels):
            results.append(res)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=4)


def test_auth():
    with open("data/raw.json", "r", encoding="utf-8") as file:
        json_data = json.load(file)
        for channel in json_data:
            if channel.get("ChannelName") == "ç¯çƒæ—…æ¸¸æ ‡æ¸…":
                match = re.search(r"rtsp://\S+", channel["ChannelSDP"])
                if match:
                    tmp = match.group(0)
                    redirected = get_redirected_rtsp_url(tmp)
                    if redirected.startswith("rtsp://222"):
                        print("éœ€è¦é‰´æƒ")
                    else:
                        print("æ— éœ€é‰´æƒ")


def json_to_md_table(json_file="data/iptv.json", md_file="data/channels.md"):
    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    total_channels = len(data)

    tz_utc8 = timezone(timedelta(hours=8))
    now_str = datetime.now(tz=tz_utc8).strftime("%Y-%m-%d %H:%M:%S")

    lines = [
        "## ğŸ“º é¢‘é“åˆ—è¡¨\n",
        f"**æ›´æ–°æ—¶é—´**: {now_str} UTC+8\n\n"
        f"**é¢‘é“æ€»æ•°**: {total_channels}\n\n"
        "| é¢‘é“åç§° | é¢‘é“å· | ç»„æ’­å· |",
        "|----------|--------|--------|",
    ]

    for ch in data:
        name = ch.get("ChannelName", "")
        tvg_id = ch.get("tvg_id", "")

        channel_url = ch.get("udpxy_url", "")
        mcast_number = ""
        if channel_url.startswith("rtp://"):
            match = re.search(r"\.(\d+):\d+$", channel_url)
            if match:
                mcast_number = match.group(1)

        lines.append(f"| {name} | {tvg_id} | {mcast_number} |")

    with open(md_file, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    print("é¢‘é“åˆ—è¡¨ Markdown æ–‡ä»¶ å·²ç”Ÿæˆ")
